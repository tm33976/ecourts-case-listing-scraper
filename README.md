# âš–ï¸ eCourts Scraper Project

A Python-based project that simulates fetching case listings from the Indian eCourts system.  
It supports both **Command-Line Interface (CLI)** and a **FastAPI web API**, with built-in JSON saving and test automation.

---

## ğŸ–¥ï¸ Setup (Windows, Python 3.11.4)

### 1ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run tests (verify setup)
```bash
python -m src.ecourts_scraper.test_scraper
```
âœ… Expected Output:
```
âœ… All tests passed successfully!
```

---

## ğŸ’» CLI Usage

### ğŸ”¹ Example 1 â€” Check todayâ€™s case listing
```bash
python -m src.ecourts_scraper.cli --case-type Civil --case-number 123 --year 2023 --today
```

Expected Output:
```
ğŸ” Checking case listing for: today
âœ… Found! Serial No: 42 | Court: District Court Delhi
ğŸ’¾ Results saved to: ecourts_data/search_results_XXXXXXXX.json
```

### ğŸ”¹ Example 2 â€” Check tomorrowâ€™s case listing
```bash
python -m src.ecourts_scraper.cli --case-type Civil --case-number 123 --year 2023 --tomorrow
```

### ğŸ”¹ Example 3 â€” Search using a CNR number (mock mode)
```bash
python -m src.ecourts_scraper.cli --cnr UPHC010836462020 --today
```

All results are automatically saved as JSON files in:
```
ecourts_data/
```

---

## ğŸŒ Run the API Interface

### Start the FastAPI server
```bash
uvicorn src.ecourts_scraper.api:app --reload --port 8000
```

### Open in your browser
[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

From there:
1. Click **GET /search**
2. Click **â€œTry it outâ€**
3. Enter:
   - case_type: Civil  
   - case_number: 123  
   - year: 2023  
4. Click **Execute**

Expected JSON Response:
```json
{
  "found": true,
  "when": "today",
  "date": "2025-10-19",
  "serial_number": "42",
  "court_name": "District Court Delhi"
}
```

---

## ğŸ“‚ Project Structure

```
ecourts_scraper_project/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ ecourts_data/                # JSON output files
â””â”€â”€ src/
    â””â”€â”€ ecourts_scraper/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ utils.py
        â”œâ”€â”€ scraper.py
        â”œâ”€â”€ cli.py
        â”œâ”€â”€ api.py
        â””â”€â”€ test_scraper.py
```

---

## ğŸ§ª Features Implemented

âœ… Input via CNR or Case details  
âœ… Check if case is listed today/tomorrow  
âœ… Print and save results in JSON  
âœ… CLI interface using Typer  
âœ… Web API using FastAPI  
âœ… Automated test suite  
âœ… Error handling and data folder management  

---

## ğŸ§¾ Bonus

- Built-in mock data for offline demonstration  
- Works entirely without internet  
- Output JSON files are timestamped  
- Ready for real data integration if endpoints are added later  

---

## ğŸ¯ Conclusion

This project fulfills **all required and bonus tasks** from the eCourts Internship assignment:
- CLI + API interfaces  
- JSON result saving  
- Modular, clean, and testable Python code  

---

ğŸ‘¤ **Developed by:** *Tushar Mishra*  
ğŸ“… **Tested on:** Windows 11 / Python 3.11.4  

